{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "- [TensorFlow Example - convolution network](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/3%20-%20Neural%20Networks/convolutional_network.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/gzip.py:274: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "  return self._buffer.read(size)\n",
      "/Users/Dongjun/DLselfProjects/4.Convolution_Network/input_data.py:41: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "  data = data.reshape(num_images, rows, cols, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./../data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting ./../data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting ./../data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./../data/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"./../data/MNIST/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "num_iters = 1000\n",
    "batch_size = 64\n",
    "display_step = 20\n",
    "\n",
    "geometry = [28, 28]\n",
    "classes = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "num_classes = len(classes)\n",
    "dropout_prob = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tensor Flow Graph Input\n",
    "X = tf.placeholder(tf.float32, [None, geometry[0]*geometry[1]])\n",
    "y = tf.placeholder(tf.float32, [None, num_classes])\n",
    "dropout = tf.placeholder(tf.float32)\n",
    "\n",
    "# AlexNet Weight & bias\n",
    "# 3x3 conv, 1 input, 64 outputs\n",
    "Wc1 = tf.Variable(tf.random_normal([3, 3, 1, 64]))\n",
    "bc1 = tf.Variable(tf.random_normal([64]))\n",
    "\n",
    "# 3x3 conv, 64 input, 128 outputs\n",
    "Wc2 = tf.Variable(tf.random_normal([3, 3, 64, 128]))\n",
    "bc2 = tf.Variable(tf.random_normal([128]))\n",
    "\n",
    "# 3x3 conv, 128 input, 256 outputs\n",
    "Wc3 = tf.Variable(tf.random_normal([3, 3, 128, 256]))\n",
    "bc3 = tf.Variable(tf.random_normal([256]))\n",
    "\n",
    "# Fully connected (Standard 3-layer MLP), 4*4*256 input, 1024 \n",
    "Wf1 = tf.Variable(tf.random_normal([4*4*256, 1024]))\n",
    "bf1 = tf.Variable(tf.random_normal([1024]))\n",
    "\n",
    "Wf2 = tf.Variable(tf.random_normal([1024, 1024]))\n",
    "bf2 = tf.Variable(tf.random_normal([1024]))\n",
    "\n",
    "Wout = tf.Variable(tf.random_normal([1024, num_classes]))\n",
    "bout = tf.Variable(tf.random_normal([num_classes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convolution Network\n",
    "\n",
    "# Reshape input picture\n",
    "input_X = tf.reshape(X, shape=[-1, 28, 28, 1])\n",
    "\n",
    "# Stage 1 : Convolution -> ReLU -> Max Pooling -> Local Response Normalization -> Dropout\n",
    "conv1 = tf.nn.conv2d(input_X, Wc1, strides = [1, 1, 1, 1], padding='SAME')\n",
    "conv1 = tf.nn.relu(tf.nn.bias_add(conv1, bc1))\n",
    "conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides = [1, 2, 2, 1], padding='SAME')\n",
    "conv1 = tf.nn.lrn(conv1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm1')\n",
    "conv1 = tf.nn.dropout(conv1, dropout)\n",
    "\n",
    "# Stage 2 : Convolution -> ReLU -> Max Pooling -> Local Response Normalization -> Dropout\n",
    "conv2 = tf.nn.conv2d(conv1, Wc2, strides = [1, 1, 1, 1], padding='SAME')\n",
    "conv2 = tf.nn.relu(tf.nn.bias_add(conv2, bc2))\n",
    "conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides = [1, 2, 2, 1], padding='SAME')\n",
    "conv2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm2')\n",
    "conv2 = tf.nn.dropout(conv2, dropout)\n",
    "\n",
    "# Stage 3 : Convolution -> ReLU -> Max Pooling -> Local Response Normalization -> Dropout\n",
    "conv3 = tf.nn.conv2d(conv2, Wc3, strides = [1, 1, 1, 1], padding='SAME')\n",
    "conv3 = tf.nn.relu(tf.nn.bias_add(conv3, bc3))\n",
    "conv3 = tf.nn.max_pool(conv3, ksize=[1, 2, 2, 1], strides = [1, 2, 2, 1], padding='SAME')\n",
    "conv3 = tf.nn.lrn(conv3, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm3')\n",
    "conv3 = tf.nn.dropout(conv3, dropout)\n",
    "\n",
    "# Stage 4 : Fully connected : Linear -> ReLU -> Linear\n",
    "fc1 = tf.reshape(conv3, [-1, Wf1.get_shape().as_list()[0]])\n",
    "fc1 = tf.nn.relu(tf.add(tf.matmul(fc1, Wf1), bf1))\n",
    "fc2 = tf.nn.relu(tf.add(tf.matmul(fc1, Wf2), bf2))\n",
    "\n",
    "out = tf.add(tf.matmul(fc2, Wout), bout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(out, y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(out, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  1  loss= 444836.0\n",
      "Epoch :  4  loss= 227315.0\n",
      "Epoch :  5  loss= 232778.0\n",
      "Epoch :  8  loss= 246281.0\n",
      "Epoch :  9  loss= 318405.0\n",
      "Epoch :  12  loss= 249907.0\n",
      "Epoch :  13  loss= 223002.0\n",
      "Epoch :  64  loss= 48886.3\n",
      "Epoch :  65  loss= 58316.8\n",
      "Epoch :  68  loss= 51808.5\n",
      "Epoch :  69  loss= 76427.7\n",
      "Epoch :  72  loss= 66886.8\n",
      "Epoch :  73  loss= 45391.0\n",
      "Epoch :  76  loss= 63847.1\n",
      "Epoch :  77  loss= 67378.5\n",
      "Epoch :  128  loss= 36863.5\n",
      "Epoch :  129  loss= 19753.3\n",
      "Epoch :  132  loss= 34401.7\n",
      "Epoch :  133  loss= 40443.7\n",
      "Epoch :  136  loss= 28097.6\n",
      "Epoch :  137  loss= 26450.4\n",
      "Epoch :  140  loss= 32991.9\n",
      "Epoch :  141  loss= 35142.5\n",
      "Epoch :  192  loss= 13157.4\n",
      "Epoch :  193  loss= 15387.5\n",
      "Epoch :  196  loss= 28913.2\n",
      "Epoch :  197  loss= 25020.9\n",
      "Epoch :  200  loss= 36318.1\n",
      "Epoch :  201  loss= 26157.6\n",
      "Epoch :  204  loss= 21696.4\n",
      "Epoch :  205  loss= 19616.4\n",
      "Epoch :  256  loss= 18939.2\n",
      "Epoch :  257  loss= 33669.5\n",
      "Epoch :  260  loss= 15434.4\n",
      "Epoch :  261  loss= 15662.2\n",
      "Epoch :  264  loss= 12715.0\n",
      "Epoch :  265  loss= 11291.6\n",
      "Epoch :  268  loss= 21806.3\n",
      "Epoch :  269  loss= 26559.9\n",
      "Epoch :  320  loss= 14455.2\n",
      "Epoch :  321  loss= 13148.7\n",
      "Epoch :  324  loss= 5155.78\n",
      "Epoch :  325  loss= 17517.5\n",
      "Epoch :  328  loss= 17534.9\n",
      "Epoch :  329  loss= 10566.0\n",
      "Epoch :  332  loss= 11410.6\n",
      "Epoch :  333  loss= 12824.7\n",
      "Epoch :  384  loss= 16796.7\n",
      "Epoch :  385  loss= 22743.1\n",
      "Epoch :  388  loss= 13349.7\n",
      "Epoch :  389  loss= 14137.4\n",
      "Epoch :  392  loss= 11236.6\n",
      "Epoch :  393  loss= 12068.9\n",
      "Epoch :  396  loss= 10578.1\n",
      "Epoch :  397  loss= 13861.1\n",
      "Epoch :  448  loss= 14778.6\n",
      "Epoch :  449  loss= 9695.42\n",
      "Epoch :  452  loss= 6295.84\n",
      "Epoch :  453  loss= 1297.3\n",
      "Epoch :  456  loss= 3962.44\n",
      "Epoch :  457  loss= 6410.39\n",
      "Epoch :  460  loss= 9262.58\n",
      "Epoch :  461  loss= 8649.21\n",
      "Epoch :  512  loss= 12641.0\n",
      "Epoch :  513  loss= 11566.6\n",
      "Epoch :  516  loss= 7182.37\n",
      "Epoch :  517  loss= 6809.16\n",
      "Epoch :  520  loss= 10705.2\n",
      "Epoch :  521  loss= 14588.8\n",
      "Epoch :  524  loss= 14311.7\n",
      "Epoch :  525  loss= 9036.11\n",
      "Epoch :  576  loss= 8504.0\n",
      "Epoch :  577  loss= 8619.23\n",
      "Epoch :  580  loss= 13361.6\n",
      "Epoch :  581  loss= 7647.55\n",
      "Epoch :  584  loss= 19024.4\n",
      "Epoch :  585  loss= 13676.4\n",
      "Epoch :  588  loss= 3827.39\n",
      "Epoch :  589  loss= 9622.14\n",
      "Epoch :  640  loss= 9682.11\n",
      "Epoch :  641  loss= 7799.87\n",
      "Epoch :  644  loss= 8171.64\n",
      "Epoch :  645  loss= 11039.5\n",
      "Epoch :  648  loss= 4247.81\n",
      "Epoch :  649  loss= 6373.63\n",
      "Epoch :  652  loss= 4485.87\n",
      "Epoch :  653  loss= 9228.69\n",
      "Epoch :  704  loss= 5940.41\n",
      "Epoch :  705  loss= 6868.06\n",
      "Epoch :  708  loss= 6037.89\n",
      "Epoch :  709  loss= 18084.7\n",
      "Epoch :  712  loss= 5430.76\n",
      "Epoch :  713  loss= 14094.6\n",
      "Epoch :  716  loss= 9295.55\n",
      "Epoch :  717  loss= 7405.67\n",
      "Epoch :  768  loss= 4757.76\n",
      "Epoch :  769  loss= 5443.1\n",
      "Epoch :  772  loss= 7308.17\n",
      "Epoch :  773  loss= 5789.02\n",
      "Epoch :  776  loss= 5961.7\n",
      "Epoch :  777  loss= 5182.06\n",
      "Epoch :  780  loss= 10584.3\n",
      "Epoch :  781  loss= 11433.2\n",
      "Epoch :  832  loss= 1511.67\n",
      "Epoch :  833  loss= 1708.82\n",
      "Epoch :  836  loss= 5589.32\n",
      "Epoch :  837  loss= 6285.01\n",
      "Epoch :  840  loss= 1525.64\n",
      "Epoch :  841  loss= 3925.26\n",
      "Epoch :  844  loss= 1571.08\n",
      "Epoch :  845  loss= 1344.12\n",
      "Epoch :  896  loss= 12422.1\n",
      "Epoch :  897  loss= 4721.93\n",
      "Epoch :  900  loss= 7446.11\n",
      "Epoch :  901  loss= 7809.38\n",
      "Epoch :  904  loss= 6404.41\n",
      "Epoch :  905  loss= 8689.32\n",
      "Epoch :  908  loss= 7023.53\n",
      "Epoch :  909  loss= 4939.59\n",
      "Epoch :  960  loss= 5763.75\n",
      "Epoch :  961  loss= 5408.38\n",
      "Epoch :  964  loss= 8281.18\n",
      "Epoch :  965  loss= 7006.0\n",
      "Epoch :  968  loss= 6623.79\n",
      "Epoch :  969  loss= 3496.29\n",
      "Epoch :  972  loss= 5571.53\n",
      "Epoch :  973  loss= 4864.87\n",
      "Optimization Finishied\n",
      "Testing Accuracy: 0.8423\n"
     ]
    }
   ],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# Launch the Graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    # Train\n",
    "    for epoch in range(1, num_iters+1):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        # Fit training data\n",
    "        \n",
    "        sess.run(optimizer, feed_dict={X: batch_xs, y: batch_ys, dropout: dropout_prob})\n",
    "        \n",
    "        if epoch & 50 == 0:\n",
    "            loss = sess.run(cost, feed_dict={X: batch_xs, y: batch_ys, dropout: 1.})\n",
    "            print(\"Epoch : \", epoch, \" loss=\" , loss)\n",
    "    \n",
    "    print(\"Optimization Finishied\")\n",
    "    \n",
    "    # Test\n",
    "    print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={X: mnist.test.images, \n",
    "                                                             y: mnist.test.labels, \n",
    "                                                             dropout: 1.}) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
